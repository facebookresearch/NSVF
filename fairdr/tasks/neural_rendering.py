# Copyright (c) Facebook, Inc. and its affiliates.
#
# This source code is licensed under the MIT license found in the
# LICENSE file in the root directory of this source tree.
import torch
import numpy as np

from fairseq.tasks import FairseqTask, register_task
from fairdr.data import (
    ShapeViewDataset, SampledPixelDataset, WorldCoordDataset, ShapeDataset
)
from fairdr.data.data_utils import write_images
from fairdr.renderer import NeuralRenderer


@register_task("single_object_rendering")
class SingleObjRenderingTask(FairseqTask):
    """
    Task for remembering & rendering a single object.
    """
    @staticmethod
    def add_args(parser):
        """Add task-specific arguments to the parser"""
        parser.add_argument("data", help='data-path or data-directoy')
        parser.add_argument("--load-depth", action="store_true", 
                            help="load depth images if exists")
        parser.add_argument("--load-point", action="store_true",
                            help="load sparse voxel generated by visual-hull if exists")
        parser.add_argument("--load-mask", action="store_true",
                            help="load pre-computed masks which is useful for subsampling during training.")
        parser.add_argument("--max-train-view", type=int, default=50, 
                            help="number of views sampled for training, can be unlimited if set -1")
        parser.add_argument("--view-per-batch", type=int, default=6,
                            help="number of views training each batch (each GPU)")
        parser.add_argument("--pixel-per-view", default=None, nargs='?', const=16384, type=int,
                            help="how many pixels to sample from each view. -1 means using all pixels")
        parser.add_argument("--sampling-on-mask", default=1.0, nargs='?', const=0.9, type=float,
                            help="this value determined the probability of sampling rays on masks")
        parser.add_argument("--view-resolution", type=int, default=64,
                            help="height/width for the squared image. downsampled from the original.")

    def __init__(self, args):
        super().__init__(args)
        
        if getattr(args, "distributed_rank", -1) == 0:
            from tensorboardX import SummaryWriter
            self.writer = SummaryWriter(self.args.tensorboard_logdir)
        else:
            self.writer = None

    @classmethod
    def setup_task(cls, args, **kwargs):
        """
        Setup the task
        """
        return cls(args)

    def load_dataset(self, split, **kwargs):
        """
        Load a given dataset split (train, valid, test)
        """

        if split != 'test':
            repeats = int(np.ceil(self.args.max_train_view / 
                            self.args.view_per_batch / 
                            self.args.distributed_world_size
                            ) * self.args.distributed_world_size)

            self.datasets[split] = ShapeViewDataset(
                self.args.data,
                self.args.max_train_view,
                self.args.view_per_batch,
                self.args.view_resolution,
                train=(split == 'train'),
                load_depth=self.args.load_depth,
                load_mask=self.args.load_mask,
                load_point=self.args.load_point,
                repeat=repeats)
                
            if split == 'train' and (self.args.pixel_per_view is not None):
                self.datasets[split] = SampledPixelDataset(
                    self.datasets[split],
                    self.args.pixel_per_view,
                    self.args.sampling_on_mask)

            self.datasets[split] = WorldCoordDataset(
                self.datasets[split]
            )
        else:
            self.datasets[split] = ShapeDataset(
                self.args.data,
                load_point=self.args.load_point)

    def build_generator(self, args):
        """
        build a neural renderer for visualization
        """
        return NeuralRenderer()

    
    @property
    def source_dictionary(self):
        """Return the :class:`~fairseq.data.Dictionary` for the language
        model."""
        return None
    
    @property
    def target_dictionary(self):
        """Return the :class:`~fairseq.data.Dictionary` for the language
        model."""
        return None

    def valid_step(self, sample, model, criterion):
        # set_trace()
        loss, sample_size, logging_output = super().valid_step(sample, model, criterion)
        
        # visualize in tensorboard
        images = model.visualize(sample)
        if images is not None and self.args.distributed_rank == 0:
            write_images(self.writer, images)

        return loss, sample_size, logging_output
    